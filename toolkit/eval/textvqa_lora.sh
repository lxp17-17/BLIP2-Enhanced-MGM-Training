#!/bin/bash
# LoRAæ¨¡å‹TextVQAè¯„ä¼°è„šæœ¬

SCRIPT_DIR=$(cd "$(dirname "$0")" && pwd)

CKPT=$1
output_dir=$SCRIPT_DIR/../../output/eval_results/$CKPT/textvqa/

CUDA_VISIBLE_DEVICES=$2
gpu_list="${CUDA_VISIBLE_DEVICES:-0}"
IFS=',' read -ra GPULIST <<< "$gpu_list"

CHUNKS=${#GPULIST[@]}

echo "ğŸš€ å¼€å§‹LoRA TextVQAè¯„ä¼°"
echo "ğŸ“ æ¨¡å‹: $CKPT"
echo "ğŸ–¥ï¸  GPU: $gpu_list"
echo "ğŸ“Š åˆ†å—æ•°: $CHUNKS"

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p $output_dir

for IDX in $(seq 0 $((CHUNKS-1))); do
    echo "ğŸ”„ å¯åŠ¨åˆ†å— $IDX/$((CHUNKS-1))"
    CUDA_VISIBLE_DEVICES=${GPULIST[$IDX]} python $SCRIPT_DIR/../eval_lora_textvqa.py \
        --model-path $SCRIPT_DIR/../../output/training_dirs/$CKPT \
        --question-file $SCRIPT_DIR/../training/data/eval_stage_1/textvqa/llava_textvqa_val_v051_ocr.jsonl \
        --image-folder $SCRIPT_DIR/../training/data/eval_stage_1/textvqa/train_images \
        --answers-file $output_dir/${CHUNKS}_${IDX}.jsonl \
        --num-chunks $CHUNKS \
        --chunk-idx $IDX \
        --temperature 0 \
        --conv-mode gemma &
done

echo "â³ ç­‰å¾…æ‰€æœ‰åˆ†å—å®Œæˆ..."
wait

echo "ğŸ”— åˆå¹¶ç»“æœæ–‡ä»¶..."
# Clear out the output file if it exists.
> "$output_dir/results.jsonl"

# Loop through the indices and concatenate each file.
for IDX in $(seq 0 $((CHUNKS-1))); do
    if [ -f "$output_dir/${CHUNKS}_${IDX}.jsonl" ]; then
        cat $output_dir/${CHUNKS}_${IDX}.jsonl >> "$output_dir/results.jsonl"
        echo "  âœ… åˆå¹¶åˆ†å— $IDX"
    else
        echo "  âŒ åˆ†å— $IDX æ–‡ä»¶ä¸å­˜åœ¨"
    fi
done

# ç»Ÿè®¡ç»“æœ
if [ -f "$output_dir/results.jsonl" ]; then
    result_count=$(wc -l < "$output_dir/results.jsonl")
    echo "ğŸ“Š è¯„ä¼°å®Œæˆ: $result_count ä¸ªç»“æœ"
    echo "ğŸ“ ç»“æœæ–‡ä»¶: $output_dir/results.jsonl"
else
    echo "âŒ ç»“æœæ–‡ä»¶ç”Ÿæˆå¤±è´¥"
    exit 1
fi

echo "âœ… LoRA TextVQAè¯„ä¼°å®Œæˆï¼"
