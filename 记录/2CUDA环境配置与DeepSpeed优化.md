# CUDAç¯å¢ƒé…ç½®ä¸DeepSpeedä¼˜åŒ–æŒ‡å—

## ğŸ”§ CUDAç¯å¢ƒé…ç½®

### é—®é¢˜èƒŒæ™¯
åœ¨å¤šæ¨¡æ€æ¨¡å‹è®­ç»ƒä¸­ï¼ŒCUDAç‰ˆæœ¬ä¸åŒ¹é…ä¼šå¯¼è‡´DeepSpeedç¼–è¯‘å¤±è´¥ï¼Œè¿›è€Œå½±å“è®­ç»ƒç¨³å®šæ€§ã€‚

### è§£å†³æ–¹æ¡ˆ

#### 1. æ£€æŸ¥å½“å‰ç¯å¢ƒ
```bash
# æ£€æŸ¥PyTorch CUDAç‰ˆæœ¬
python -c "import torch; print(f'PyTorch CUDA: {torch.version.cuda}')"

# æ£€æŸ¥ç³»ç»ŸCUDAç‰ˆæœ¬ï¼ˆå¦‚æœå·²å®‰è£…ï¼‰
nvcc --version

# æ£€æŸ¥GPUçŠ¶æ€
nvidia-smi
```

#### 2. å®‰è£…åŒ¹é…çš„CUDA Toolkit
```bash
# ç¡®ä¿åœ¨æ­£ç¡®çš„condaç¯å¢ƒä¸­
conda info --envs

# å®‰è£…CUDA 12.4ï¼ˆåŒ¹é…PyTorchï¼‰
conda install -c "nvidia/label/cuda-12.4.0" cuda-toolkit -y

# éªŒè¯å®‰è£…
nvcc --version
```

#### 3. ç¯å¢ƒå˜é‡è®¾ç½®
```bash
export CUDA_VISIBLE_DEVICES=0
export DS_BUILD_OPS=0
export DS_SKIP_CUDA_CHECK=1
export PYTHONPATH="$SCRIPT_DIR/training:$PYTHONPATH"
```

## âš¡ DeepSpeedé…ç½®ä¼˜åŒ–

### ZeRO-2é…ç½®æ–‡ä»¶
`toolkit/training/scripts/zero2_offload.json`:
```json
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },
    "bf16": {
        "enabled": "auto"
    },
    "train_micro_batch_size_per_gpu": "auto",
    "train_batch_size": "auto", 
    "gradient_accumulation_steps": "auto",
    "zero_optimization": {
        "stage": 2,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu", 
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto"
    }
}
```

### å…³é”®ä¼˜åŒ–ç­–ç•¥

#### 1. å†…å­˜ä¼˜åŒ–
- **CPU Offload**: å°†ä¼˜åŒ–å™¨å’Œå‚æ•°offloadåˆ°CPU
- **Gradient Checkpointing**: å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
- **Mixed Precision**: ä½¿ç”¨bf16å‡å°‘æ˜¾å­˜å ç”¨

#### 2. æ‰¹æ¬¡å¤§å°è°ƒä¼˜
```bash
# ä¿å®ˆé…ç½®ï¼ˆæ¨èï¼‰
BATCH_SIZE_PER_GPU=1
GRADIENT_ACCUMULATION_STEPS=128
DATALOADER_NUM_WORKERS=1

# æ¿€è¿›é…ç½®ï¼ˆå¯èƒ½OOMï¼‰
BATCH_SIZE_PER_GPU=4
GRADIENT_ACCUMULATION_STEPS=32
DATALOADER_NUM_WORKERS=4
```

#### 3. æ¨¡å‹é…ç½®ä¼˜åŒ–
```bash
--model_max_length 1024          # å‡å°‘åºåˆ—é•¿åº¦
--gradient_checkpointing True     # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
--bf16 True                      # ä½¿ç”¨æ··åˆç²¾åº¦
--lazy_preprocess True           # å»¶è¿Ÿæ•°æ®é¢„å¤„ç†
```

## ğŸš€ è®­ç»ƒå¯åŠ¨å‘½ä»¤

### æ ‡å‡†å¯åŠ¨
```bash
PYTHONPATH=$SCRIPT_DIR/training:$PYTHONPATH \
DS_BUILD_OPS=0 DS_SKIP_CUDA_CHECK=1 \
python $(which deepspeed) $SCRIPT_DIR/training/mgm/train/train_mem.py \
    --deepspeed $SCRIPT_DIR/training/scripts/zero2_offload.json \
    --model_name_or_path $MODEL_PATH \
    --version gemma \
    --data_path $DATA_PATH \
    --image_folder $IMAGE_FOLDER \
    --pretrain_mm_mlp_adapter $PRETRAIN_MODEL \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 128 \
    --gradient_checkpointing True \
    --bf16 True \
    --model_max_length 1024 \
    --dataloader_num_workers 1 \
    --lazy_preprocess True
```

### è°ƒè¯•å¯åŠ¨ï¼ˆæœ€å°é…ç½®ï¼‰
```bash
# ç”¨äºå¿«é€ŸéªŒè¯çš„æœ€å°é…ç½®
--per_device_train_batch_size 1
--gradient_accumulation_steps 16
--max_steps 10
--save_steps 5
--dataloader_num_workers 1
--model_max_length 1024
```

## ğŸ“Š èµ„æºç›‘æ§

### å®æ—¶ç›‘æ§å‘½ä»¤
```bash
# GPUä½¿ç”¨æƒ…å†µ
watch -n 1 nvidia-smi

# å†…å­˜ä½¿ç”¨æƒ…å†µ  
watch -n 1 free -h

# è¿›ç¨‹ç›‘æ§
htop
```

### å…³é”®æŒ‡æ ‡
- **GPUæ˜¾å­˜ä½¿ç”¨ç‡**: å»ºè®®ä¿æŒåœ¨80%ä»¥ä¸‹
- **ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡**: å»ºè®®ä¿æŒåœ¨70%ä»¥ä¸‹
- **è¿›ç¨‹çŠ¶æ€**: é¿å…å‡ºç°è¿”å›ç -9ï¼ˆè¢«æ€æ­»ï¼‰

## âš ï¸ å¸¸è§é—®é¢˜ä¸è§£å†³

### 1. CUDAç‰ˆæœ¬ä¸åŒ¹é…
```
[WARNING] DeepSpeed Op Builder: Installed CUDA version 11.5 does not match torch 12.4
```
**è§£å†³**: å®‰è£…åŒ¹é…çš„CUDA toolkit

### 2. è¿›ç¨‹è¢«æ€æ­»ï¼ˆè¿”å›ç -9ï¼‰
```
exits with return code = -9
```
**è§£å†³**: å‡å°‘batch sizeå’Œworkeræ•°é‡

### 3. DeepSpeedç¼–è¯‘å¤±è´¥
```
Building extension module cpu_adam... FAILED
```
**è§£å†³**: è®¾ç½®ç¯å¢ƒå˜é‡ `DS_BUILD_OPS=0`

### 4. æ˜¾å­˜ä¸è¶³
```
CUDA out of memory
```
**è§£å†³**: å¯ç”¨CPU offloadå’Œgradient checkpointing

## ğŸ¯ æœ€ä½³å®è·µ

### 1. ç¯å¢ƒå‡†å¤‡
1. ç¡®ä¿condaç¯å¢ƒæ¿€æ´»
2. å®‰è£…åŒ¹é…çš„CUDA toolkit
3. éªŒè¯PyTorchå’ŒCUDAå…¼å®¹æ€§

### 2. é…ç½®ç­–ç•¥
1. ä»ä¿å®ˆå‚æ•°å¼€å§‹
2. é€æ­¥è°ƒä¼˜æ€§èƒ½
3. ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µ

### 3. è°ƒè¯•æµç¨‹
1. å…ˆè¿è¡Œæœ€å°æµ‹è¯•
2. ç¡®è®¤åŸºç¡€åŠŸèƒ½æ­£å¸¸
3. å†è¿›è¡Œå®Œæ•´è®­ç»ƒ

---

**æ›´æ–°æ—¥æœŸ**: 2025-07-01  
**é€‚ç”¨ç¯å¢ƒ**: CUDA 12.4 + PyTorch 2.5.1 + DeepSpeed  
**æµ‹è¯•çŠ¶æ€**: å·²éªŒè¯
